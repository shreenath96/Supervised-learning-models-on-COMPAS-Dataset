{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84617d8b",
   "metadata": {},
   "source": [
    "# IMPORTING PACKAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "384a5255",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import linear_model, decomposition, datasets\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from fairlearn.metrics import demographic_parity_difference\n",
    "from fairlearn.reductions import ExponentiatedGradient, DemographicParity\n",
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137ea31c",
   "metadata": {},
   "source": [
    "# READING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4b0e6fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns in the dataset are :  53\n",
      "Number of columns after numeric conversion :  31\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(\"recid.csv\")\n",
    "num_cols = train.shape[1]\n",
    "print(\"Number of columns in the dataset are : \",num_cols)\n",
    "train_new = train.drop(['id','name','first','last','compas_screening_date','dob','c_offense_date','c_arrest_date','r_case_number','r_charge_degree',\n",
    "                'r_days_from_arrest','r_offense_date','r_charge_desc','r_jail_in','r_jail_out','violent_recid','start','end','vr_case_number',\n",
    "                'vr_charge_degree','v_type_of_assessment','vr_offense_date','vr_charge_desc','screening_date','days_b_screening_arrest',\n",
    "                'c_jail_in','c_jail_out','c_case_number','c_days_from_compas','v_screening_date','c_charge_desc','in_custody','out_custody',\n",
    "                'type_of_assessment','is_recid'],axis=1)\n",
    "train_final = pd.get_dummies(train_new)\n",
    "num_cols = train_final.shape[1]\n",
    "print(\"Number of columns after numeric conversion : \",num_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a743c01d",
   "metadata": {},
   "source": [
    "# REMOVING SENSITIVE FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "708a3b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_new = train.drop(['race'],axis=1)\n",
    "# num_cols = train_new.shape[1]\n",
    "# print(\"Number of columns in the dataset after removing unwanted columns are : \",num_cols)\n",
    "# train_new.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461742e0",
   "metadata": {},
   "source": [
    "# TRAIN TEST SPLIT ON DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e2697aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (4833, 30)\n",
      "Shape of X_test: (2381, 30)\n",
      "Shape of y_train: (4833,)\n",
      "Shape of y_test: (2381,)\n"
     ]
    }
   ],
   "source": [
    "train_final = train_final.drop('two_year_recid',axis=1)\n",
    "X = train_final\n",
    "Y = train['two_year_recid']\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,Y,test_size=0.33,random_state=18)\n",
    "X_train_no_race = X_train.drop(['race_African-American', 'race_Asian',\n",
    "    'race_Caucasian', 'race_Hispanic', 'race_Native American', 'race_Other'],axis=1)\n",
    "X_test_no_race = X_test.drop(['race_African-American', 'race_Asian',\n",
    "    'race_Caucasian', 'race_Hispanic', 'race_Native American', 'race_Other'],axis=1)\n",
    "X_test_no_race.columns\n",
    "print(\"Shape of X_train:\", X_train.shape)\n",
    "print(\"Shape of X_test:\", X_test.shape)\n",
    "print(\"Shape of y_train:\", y_train.shape)\n",
    "print(\"Shape of y_test:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7bface",
   "metadata": {},
   "source": [
    "# TRAINING LOGISTIC REGRESSION MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7afc468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9042419151616967\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.95      0.92      1312\n",
      "           1       0.93      0.85      0.89      1069\n",
      "\n",
      "    accuracy                           0.90      2381\n",
      "   macro avg       0.91      0.90      0.90      2381\n",
      "weighted avg       0.91      0.90      0.90      2381\n",
      "\n",
      "                    predicted_recividated  predicted_not_recividated\n",
      "is_recividated                        910                        159\n",
      "is_not_recividated                     69                       1243\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(max_iter=1000, solver='lbfgs', penalty='l2', random_state=18, n_jobs=-1, class_weight='balanced')\n",
    "\n",
    "logreg.fit(X_train_no_race, y_train)\n",
    "y_pred_no_race = logreg.predict(X_test_no_race)\n",
    "accuracy = accuracy_score(y_test, y_pred_no_race)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(classification_report(y_test,y_pred_no_race))\n",
    "cm=np.array(confusion_matrix(y_test,y_pred_no_race,labels=[1,0]))\n",
    "confusion=pd.DataFrame(cm,index=['is_recividated','is_not_recividated'],columns=['predicted_recividated','predicted_not_recividated'])\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e97e503",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "596"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Predicted +ve and are categorized as African American by the race variable\"\"\"\n",
    "X_test[y_pred_no_race == 1]['race_African-American'].value_counts()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5f786f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "285"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Predicted +ve and are categorized as Caucasian by the race variable\"\"\"\n",
    "X_test[y_pred_no_race == 1]['race_Caucasian'].value_counts()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a5c058ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         True positive predictions by the model             \n",
      "African-American         :  556\n",
      "Caucasian                :  266\n",
      "Total True Positives     :  910\n",
      "                 % of True positives                        \n",
      "African-American         :  0.61\n",
      "Caucasian                :  0.29\n"
     ]
    }
   ],
   "source": [
    "#true positives without race variable\n",
    "true_no_race = y_test\n",
    "pred_no_race = y_pred_no_race\n",
    "\n",
    "unq_no_race = np.array([x + 2*y for x,y in zip(pred_no_race,true_no_race)])\n",
    "\n",
    "tp_no_race = np.array(np.where(unq_no_race==3)).tolist()[0]\n",
    "true_positives_no_race = X_test.iloc[tp_no_race]\n",
    "\n",
    "tp_African_no_race = true_positives_no_race['race_African-American'].value_counts()[1]\n",
    "tp_Caucasian_no_race = true_positives_no_race['race_Caucasian'].value_counts()[1]\n",
    "tp_total_no_race = true_positives_no_race.shape[0]\n",
    "\n",
    "#Predicted +ve & actually +ve\n",
    "print(\"         True positive predictions by the model             \")\n",
    "print(\"African-American         : \",tp_African_no_race)\n",
    "print(\"Caucasian                : \",tp_Caucasian_no_race)\n",
    "print(\"Total True Positives     : \",tp_total_no_race)\n",
    "\n",
    "print(\"                 % of True positives                        \")\n",
    "print(\"African-American         :  %.2f\" % (tp_African_no_race/tp_total_no_race)    )\n",
    "print(\"Caucasian                :  %.2f\" % (tp_Caucasian_no_race/tp_total_no_race)  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c1f17086",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensitive_features = np.array([X_train['race_Caucasian'], X_train['race_African-American']]).T\n",
    "sensitive_features_test = np.array([X_test['race_Caucasian'], X_test['race_African-American']]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c46cfd1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False positives for the Caucasian group:  19\n",
      "False positives for the African-American group:  40\n",
      "Total False positives are:  59\n",
      "True positives for the Caucasian group:  266\n",
      "True positives for the African-American group:  556\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Compute the confusion matrix for the Caucasian group\n",
    "cm_caucasian = confusion_matrix(y_test[sensitive_features_test[:, 0] == 1], y_pred_no_race[sensitive_features_test[:, 0] == 1])\n",
    "false_positives_caucasian = cm_caucasian[0, 1]\n",
    "\n",
    "# Compute the confusion matrix for the African-American group\n",
    "cm_african_american = confusion_matrix(y_test[sensitive_features_test[:, 1] == 1], y_pred_no_race[sensitive_features_test[:, 1] == 1])\n",
    "false_positives_african_american = cm_african_american[0, 1]\n",
    "\n",
    "print(\"False positives for the Caucasian group: \", false_positives_caucasian)\n",
    "print(\"False positives for the African-American group: \", false_positives_african_american)\n",
    "total_false_positives = false_positives_caucasian + false_positives_african_american\n",
    "print(\"Total False positives are: \", total_false_positives)\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Compute the confusion matrix for the Caucasian group\n",
    "cm_caucasian = confusion_matrix(y_test[sensitive_features_test[:, 0] == 1], y_pred_no_race[sensitive_features_test[:, 0] == 1])\n",
    "true_positives_caucasian = cm_caucasian[1, 1]\n",
    "\n",
    "# Compute the confusion matrix for the African-American group\n",
    "cm_african_american = confusion_matrix(y_test[sensitive_features_test[:, 1] == 1], y_pred_no_race[sensitive_features_test[:, 1] == 1])\n",
    "true_positives_african_american = cm_african_american[1, 1]\n",
    "\n",
    "print(\"True positives for the Caucasian group: \", true_positives_caucasian)\n",
    "print(\"True positives for the African-American group: \", true_positives_african_american)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad895e6b",
   "metadata": {},
   "source": [
    "# RANDOM FOREST MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "46ee3b17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8945821083578328\n"
     ]
    }
   ],
   "source": [
    "rf_classifier = RandomForestClassifier(n_estimators=100)\n",
    "rf_classifier.fit(X_train_no_race, y_train)\n",
    "y_pred_no_race = rf_classifier.predict(X_test_no_race)\n",
    "accuracy = accuracy_score(y_test, y_pred_no_race)\n",
    "print(accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c56d4cda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    predicted_recividated  predicted_not_recividated\n",
      "is_recividated                        932                        137\n",
      "is_not_recividated                    114                       1198\n"
     ]
    }
   ],
   "source": [
    "cm=np.array(confusion_matrix(y_test,y_pred_no_race,labels=[1,0]))\n",
    "confusion=pd.DataFrame(cm,index=['is_recividated','is_not_recividated'],columns=['predicted_recividated','predicted_not_recividated'])\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ea7f5fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensitive_features = np.array([X_train['race_Caucasian'], X_train['race_African-American']]).T\n",
    "sensitive_features_test = np.array([X_test['race_Caucasian'], X_test['race_African-American']]).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "adb3d19c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False positives for the Caucasian group:  28\n",
      "False positives for the African-American group:  64\n",
      "Total False positives are:  92\n",
      "True positives for the Caucasian group:  270\n",
      "True positives for the African-American group:  570\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Compute the confusion matrix for the Caucasian group\n",
    "cm_caucasian = confusion_matrix(y_test[sensitive_features_test[:, 0] == 1], y_pred_no_race[sensitive_features_test[:, 0] == 1])\n",
    "false_positives_caucasian = cm_caucasian[0, 1]\n",
    "\n",
    "# Compute the confusion matrix for the African-American group\n",
    "cm_african_american = confusion_matrix(y_test[sensitive_features_test[:, 1] == 1], y_pred_no_race[sensitive_features_test[:, 1] == 1])\n",
    "false_positives_african_american = cm_african_american[0, 1]\n",
    "\n",
    "print(\"False positives for the Caucasian group: \", false_positives_caucasian)\n",
    "print(\"False positives for the African-American group: \", false_positives_african_american)\n",
    "total_false_positives = false_positives_caucasian + false_positives_african_american\n",
    "print(\"Total False positives are: \", total_false_positives)\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Compute the confusion matrix for the Caucasian group\n",
    "cm_caucasian = confusion_matrix(y_test[sensitive_features_test[:, 0] == 1], y_pred_no_race[sensitive_features_test[:, 0] == 1])\n",
    "true_positives_caucasian = cm_caucasian[1, 1]\n",
    "\n",
    "# Compute the confusion matrix for the African-American group\n",
    "cm_african_american = confusion_matrix(y_test[sensitive_features_test[:, 1] == 1], y_pred_no_race[sensitive_features_test[:, 1] == 1])\n",
    "true_positives_african_american = cm_african_american[1, 1]\n",
    "\n",
    "print(\"True positives for the Caucasian group: \", true_positives_caucasian)\n",
    "print(\"True positives for the African-American group: \", true_positives_african_american)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109579cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
